{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "mount_file_id": "15u_nQkzg7ocPmEr2Y1Iq1AAqfFPr_qjT",
      "authorship_tag": "ABX9TyPuN9yTKkpKDp/owcNFNH38",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tubagokhan/ADGM/blob/main/SentenceLabelClassification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BlMqHHzi5TAd",
        "outputId": "68283574-819e-4883-f041-29d0967555a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.34.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.17.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.15,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.14.1)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.10/dist-packages (4.34.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (3.12.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.17.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.15,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.14.1)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.4.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (4.66.1)\n",
            "Requirement already satisfied: torch!=1.12.0,>=1.10 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.1.0+cu118)\n",
            "Requirement already satisfied: accelerate>=0.20.3 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.24.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.20.3->transformers[torch]) (5.9.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers[torch]) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers[torch]) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (3.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (3.1.2)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (2.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.3.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch!=1.12.0,>=1.10->transformers[torch]) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch!=1.12.0,>=1.10->transformers[torch]) (1.3.0)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.24.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.1.0+cu118)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.17.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.12.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.1)\n",
            "Requirement already satisfied: pytorchtools in /usr/local/lib/python3.10/dist-packages (0.0.2)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!pip install transformers\n",
        "!pip install transformers[torch]\n",
        "!pip install accelerate -U\n",
        "!pip install tqdm\n",
        "!pip install pytorchtools"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from tqdm import tqdm\n",
        "import json\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Use a GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load a pre-trained BERT model and tokenizer and move them to GPU\n",
        "model_name = \"bert-base-uncased\"\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "model = BertForSequenceClassification.from_pretrained(model_name, num_labels=9).to(device)\n",
        "\n",
        "# Load your JSON data\n",
        "with open('/content/drive/Othercomputers/MBZUAI/MBZUAI/Codes/COBS_ParagraphsPhrasesTags.json', 'r', encoding='utf-8-sig') as file:\n",
        "    data = json.load(file)\n",
        "\n",
        "sentences = [item[\"text\"] for item in data]\n",
        "phrases = [item[\"phrase\"] for item in data]\n",
        "labels = [item[\"t.ttype\"] for item in data]\n",
        "\n",
        "# Initialize a dictionary to store unique values and their corresponding numbers\n",
        "unique_values_dict = {}\n",
        "current_number = 0\n",
        "\n",
        "# Iterate through the list to assign numbers to unique values\n",
        "unique_values = []\n",
        "\n",
        "for value in labels:\n",
        "    if value not in unique_values_dict:\n",
        "        unique_values_dict[value] = current_number\n",
        "        current_number += 1\n",
        "    unique_values.append(unique_values_dict[value])\n",
        "\n",
        "# Print the unique values and their corresponding numbers\n",
        "for value, number in unique_values_dict.items():\n",
        "    print(f\"Value: {value}, Number: {number}\")\n",
        "\n",
        "numerical_labels = [unique_values_dict[label] for label in labels]\n",
        "\n",
        "# Tokenize and convert data to model input format\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "for sentence, phrase in zip(sentences, phrases):\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "        phrase,\n",
        "        sentence,\n",
        "        add_special_tokens=True,\n",
        "        max_length=256,\n",
        "        padding=\"max_length\",\n",
        "        return_attention_mask=True,\n",
        "        return_tensors=\"pt\",\n",
        "        truncation=True,\n",
        "    )\n",
        "    input_ids.append(encoded_dict[\"input_ids\"])\n",
        "    attention_masks.append(encoded_dict[\"attention_mask\"])\n",
        "\n",
        "# Convert the lists to PyTorch tensors\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(numerical_labels)\n",
        "\n",
        "# Split the data into training, validation, and test sets\n",
        "train_inputs, temp_inputs, train_masks, temp_masks, train_labels, temp_labels = train_test_split(\n",
        "    input_ids, attention_masks, labels, test_size=0.4, random_state=42\n",
        ")\n",
        "val_inputs, test_inputs, val_masks, test_masks, val_labels, test_labels = train_test_split(\n",
        "    temp_inputs, temp_masks, temp_labels, test_size=0.5, random_state=42\n",
        ")\n",
        "\n",
        "# Create data loaders\n",
        "batch_size = 64\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "val_data = TensorDataset(val_inputs, val_masks, val_labels)\n",
        "val_dataloader = DataLoader(val_data, batch_size=batch_size, shuffle=False)\n",
        "test_data = TensorDataset(test_inputs, test_masks, test_labels)\n",
        "test_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Set up optimizer and learning rate scheduler\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.1)\n",
        "\n",
        "# Initialize early stopping variables\n",
        "best_val_loss = float('inf')\n",
        "patience = 3\n",
        "no_improvement_count = 0\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 50\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    # Use tqdm for batch progress\n",
        "    for batch in tqdm(train_dataloader, desc=f\"Epoch {epoch + 1}/{num_epochs}\"):\n",
        "        batch_input_ids = batch[0].to(device)\n",
        "        batch_attention_masks = batch[1].to(device)\n",
        "        batch_labels = batch[2].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(\n",
        "            input_ids=batch_input_ids,\n",
        "            attention_mask=batch_attention_masks,\n",
        "            labels=batch_labels\n",
        "        )\n",
        "        loss = outputs.loss\n",
        "        total_loss += loss.item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    avg_train_loss = total_loss / len(train_dataloader)\n",
        "    print(f\"Epoch {epoch + 1}/{num_epochs}, Average Training Loss: {avg_train_loss}\")\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    total_val_loss = 0\n",
        "\n",
        "    for batch in val_dataloader:\n",
        "        batch_input_ids = batch[0].to(device)\n",
        "        batch_attention_masks = batch[1].to(device)\n",
        "        batch_labels = batch[2].to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(\n",
        "                input_ids=batch_input_ids,\n",
        "                attention_mask=batch_attention_masks,\n",
        "                labels=batch_labels\n",
        "            )\n",
        "            loss = outputs.loss\n",
        "            total_val_loss += loss.item()\n",
        "\n",
        "    avg_val_loss = total_val_loss / len(val_dataloader)\n",
        "    print(f\"Validation Loss: {avg_val_loss}\")\n",
        "\n",
        "    # Early stopping check\n",
        "    if avg_val_loss < best_val_loss:\n",
        "        best_val_loss = avg_val_loss\n",
        "        no_improvement_count = 0\n",
        "    else:\n",
        "        no_improvement_count += 1\n",
        "\n",
        "    if no_improvement_count >= patience:\n",
        "        print(\"Early stopping triggered\")\n",
        "        break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lmcjn0WZ6FIw",
        "outputId": "11cf4c53-9062-429a-8a4e-e4be5af1be7b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Value: DEF, Number: 0\n",
            "Value: RISK, Number: 1\n",
            "Value: MIT, Number: 2\n",
            "Value: ACT, Number: 3\n",
            "Value: ENT, Number: 4\n",
            "Value: TECH, Number: 5\n",
            "Value: FS, Number: 6\n",
            "Value: PERM, Number: 7\n",
            "Value: PROD, Number: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Epoch 1/50: 100%|██████████| 174/174 [48:39<00:00, 16.78s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50, Average Training Loss: 1.3723881984579152\n",
            "Validation Loss: 0.973814969432765\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/50: 100%|██████████| 174/174 [44:53<00:00, 15.48s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/50, Average Training Loss: 0.8686003595933147\n",
            "Validation Loss: 0.7734538070086775\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/50: 100%|██████████| 174/174 [45:41<00:00, 15.76s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/50, Average Training Loss: 0.7098522116055433\n",
            "Validation Loss: 0.7363370831670433\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/50: 100%|██████████| 174/174 [45:12<00:00, 15.59s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/50, Average Training Loss: 0.6306243179173305\n",
            "Validation Loss: 0.7284580027234966\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/50: 100%|██████████| 174/174 [45:31<00:00, 15.70s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/50, Average Training Loss: 0.5698804065756414\n",
            "Validation Loss: 0.7620654599419956\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/50: 100%|██████████| 174/174 [45:02<00:00, 15.53s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/50, Average Training Loss: 0.5311671903078583\n",
            "Validation Loss: 0.7933684361392054\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/50: 100%|██████████| 174/174 [45:33<00:00, 15.71s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/50, Average Training Loss: 0.501144253316967\n",
            "Validation Loss: 0.8186538907988318\n",
            "Early stopping triggered\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score,classification_report\n",
        "\n",
        "# Testing\n",
        "model.eval()\n",
        "total_test_loss = 0\n",
        "predicted_labels = []\n",
        "true_labels = []\n",
        "\n",
        "for batch in test_dataloader:\n",
        "    batch_input_ids = batch[0].to(device)\n",
        "    batch_attention_masks = batch[1].to(device)\n",
        "    batch_labels = batch[2].to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(\n",
        "            input_ids=batch_input_ids,\n",
        "            attention_mask=batch_attention_masks,\n",
        "            labels=batch_labels\n",
        "        )\n",
        "        loss = outputs.loss\n",
        "        total_test_loss += loss.item()\n",
        "\n",
        "        logits = outputs.logits\n",
        "        predicted_labels.extend(torch.argmax(logits, dim=1).tolist())\n",
        "        true_labels.extend(batch_labels.tolist())\n",
        "\n",
        "avg_test_loss = total_test_loss / len(test_dataloader)\n",
        "print(f\"Test Loss: {avg_test_loss}\")\n",
        "\n",
        "# Calculate test accuracy\n",
        "test_accuracy = accuracy_score(true_labels, predicted_labels)\n",
        "print(f\"Test Accuracy: {test_accuracy}\")\n",
        "\n",
        "# Generate classification report\n",
        "class_names = [value for value, number in unique_values_dict.items()]\n",
        "print(classification_report(true_labels, predicted_labels, target_names=class_names))\n",
        "\n",
        "# Save the trained model\n",
        "model.save_pretrained(\"/content/drive/Othercomputers/MBZUAI/MBZUAI/Codes/bert_phrase_classification_model\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M-4IFZRUCmkT",
        "outputId": "1fd1f3f5-48b1-4091-fb0e-2af12cd2bd5b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.809679130028034\n",
            "Test Accuracy: 0.6204754186925986\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         DEF       0.56      0.72      0.63      1174\n",
            "        RISK       0.65      0.61      0.63       371\n",
            "         MIT       0.83      0.76      0.79       673\n",
            "         ACT       0.65      0.67      0.66       256\n",
            "         ENT       0.52      0.27      0.35       567\n",
            "        TECH       0.49      0.54      0.51       312\n",
            "          FS       0.71      0.67      0.69       283\n",
            "        PERM       0.25      0.26      0.26        19\n",
            "        PROD       0.66      0.45      0.53        47\n",
            "\n",
            "    accuracy                           0.62      3702\n",
            "   macro avg       0.59      0.55      0.56      3702\n",
            "weighted avg       0.62      0.62      0.61      3702\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "import json\n",
        "import os\n",
        "\n",
        "# Use a GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load the saved model and tokenizer\n",
        "model_dir = \"/content/drive/Othercomputers/MBZUAI/MBZUAI/Codes/bert_phrase_classification_model\"  # Path to the saved model directory\n",
        "\n",
        "# Check if the directory exists\n",
        "if not os.path.exists(model_dir):\n",
        "    print(f\"Directory '{model_dir}' does not exist.\")\n",
        "    exit()\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "model = BertForSequenceClassification.from_pretrained(model_dir).to(device)\n",
        "\n",
        "# Load your JSON data\n",
        "with open('/content/drive/Othercomputers/MBZUAI/MBZUAI/Codes/COBS_ParagraphsPhrasesTagsSample100.json', 'r', encoding='utf-8-sig') as file:\n",
        "    data = json.load(file)\n",
        "\n",
        "# Prepare data for inference\n",
        "sentences = [item[\"text\"] for item in data]\n",
        "phrases = [item[\"phrase\"] for item in data]\n",
        "original_labels = [item[\"t.ttype\"] for item in data]\n",
        "\n",
        "# Tokenize and convert data to model input format\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "for sentence, phrase in zip(sentences, phrases):\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "        phrase,\n",
        "        sentence,\n",
        "        add_special_tokens=True,\n",
        "        max_length=128,\n",
        "        padding=\"max_length\",\n",
        "        return_attention_mask=True,\n",
        "        return_tensors=\"pt\",\n",
        "        truncation=True,\n",
        "    )\n",
        "    input_ids.append(encoded_dict[\"input_ids\"])\n",
        "    attention_masks.append(encoded_dict[\"attention_mask\"])\n",
        "\n",
        "# Convert the lists to PyTorch tensors\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "\n",
        "# Inference\n",
        "model.eval()\n",
        "predicted_labels = []\n",
        "\n",
        "for i in range(len(input_ids)):\n",
        "    input_id = input_ids[i].to(device).unsqueeze(0)\n",
        "    attention_mask = attention_masks[i].to(device).unsqueeze(0)\n",
        "\n",
        "    labelValues=['DEF', 'RISK', 'MIT', 'ACT', 'ENT', 'TECH', 'FS', 'PERM', 'PROD']\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids=input_id, attention_mask=attention_mask)\n",
        "        logits = outputs.logits\n",
        "        predicted_label = torch.argmax(logits, dim=1).item()\n",
        "        predicted_labels.append(labelValues[predicted_label])\n",
        "\n",
        "# Print the original labels and predicted labels\n",
        "for i, (original, predicted) in enumerate(zip(original_labels, predicted_labels)):\n",
        "    print(f\"Example {i + 1}:\")\n",
        "    print(f\"Sentence: {sentences[i]}\")\n",
        "    print(f\"Phrase: {phrases[i]}\")\n",
        "    print(f\"Original Label: {original}\")\n",
        "    print(f\"Predicted Label: {predicted}\\n\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cNerytPBcy7F",
        "outputId": "3eeed445-ce1b-4ae8-8e24-e31aeb968e84"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example 1:\n",
            "Sentence: $5,000 for each Cell Company; and \n",
            "Phrase: Cell\n",
            "Original Label: DEF\n",
            "Predicted Label: ENT\n",
            "\n",
            "Example 2:\n",
            "Sentence: $5,000 for each Cell Company; and \n",
            "Phrase: $5,000\n",
            "Original Label: MIT\n",
            "Predicted Label: MIT\n",
            "\n",
            "Example 3:\n",
            "Sentence: $5,000 for each Cell Company; and \n",
            "Phrase: Cell Company\n",
            "Original Label: ENT\n",
            "Predicted Label: ENT\n",
            "\n",
            "Example 4:\n",
            "Sentence: Applicants referred to in Rule 3.2.1 must also pay an annual supervision fee of $30,000 and an additional annual supervision fee of $5,000 for each additional Regulated Activity for which it has obtained a Financial Services Permission. \n",
            "Phrase: Regulated Activity\n",
            "Original Label: DEF\n",
            "Predicted Label: ACT\n",
            "\n",
            "Example 5:\n",
            "Sentence: Applicants referred to in Rule 3.2.1 must also pay an annual supervision fee of $30,000 and an additional annual supervision fee of $5,000 for each additional Regulated Activity for which it has obtained a Financial Services Permission. \n",
            "Phrase: fee\n",
            "Original Label: DEF\n",
            "Predicted Label: DEF\n",
            "\n",
            "Example 6:\n",
            "Sentence: Applicants referred to in Rule 3.2.1 must also pay an annual supervision fee of $30,000 and an additional annual supervision fee of $5,000 for each additional Regulated Activity for which it has obtained a Financial Services Permission. \n",
            "Phrase: fee\n",
            "Original Label: DEF\n",
            "Predicted Label: DEF\n",
            "\n",
            "Example 7:\n",
            "Sentence: Applicants referred to in Rule 3.2.1 must also pay an annual supervision fee of $30,000 and an additional annual supervision fee of $5,000 for each additional Regulated Activity for which it has obtained a Financial Services Permission. \n",
            "Phrase: Rule\n",
            "Original Label: DEF\n",
            "Predicted Label: DEF\n",
            "\n",
            "Example 8:\n",
            "Sentence: Applicants referred to in Rule 3.2.1 must also pay an annual supervision fee of $30,000 and an additional annual supervision fee of $5,000 for each additional Regulated Activity for which it has obtained a Financial Services Permission. \n",
            "Phrase: has obtained a Financial Services\n",
            "Original Label: MIT\n",
            "Predicted Label: MIT\n",
            "\n",
            "Example 9:\n",
            "Sentence: Applicants referred to in Rule 3.2.1 must also pay an annual supervision fee of $30,000 and an additional annual supervision fee of $5,000 for each additional Regulated Activity for which it has obtained a Financial Services Permission. \n",
            "Phrase: an additional annual supervision fee\n",
            "Original Label: MIT\n",
            "Predicted Label: MIT\n",
            "\n",
            "Example 10:\n",
            "Sentence: Applicants referred to in Rule 3.2.1 must also pay an annual supervision fee of $30,000 and an additional annual supervision fee of $5,000 for each additional Regulated Activity for which it has obtained a Financial Services Permission. \n",
            "Phrase: must also pay an annual supervision fee of $30,000\n",
            "Original Label: MIT\n",
            "Predicted Label: MIT\n",
            "\n",
            "Example 11:\n",
            "Sentence: Applicants referred to in Rule 3.2.1 must also pay an annual supervision fee of $30,000 and an additional annual supervision fee of $5,000 for each additional Regulated Activity for which it has obtained a Financial Services Permission. \n",
            "Phrase: Rule 3.2.1\n",
            "Original Label: MIT\n",
            "Predicted Label: MIT\n",
            "\n",
            "Example 12:\n",
            "Sentence: Applicants referred to in Rule 3.2.1 must also pay an annual supervision fee of $30,000 and an additional annual supervision fee of $5,000 for each additional Regulated Activity for which it has obtained a Financial Services Permission. \n",
            "Phrase: Regulated Activity\n",
            "Original Label: ACT\n",
            "Predicted Label: ACT\n",
            "\n",
            "Example 13:\n",
            "Sentence: Applicants referred to in Rule 3.2.1 must also pay an annual supervision fee of $30,000 and an additional annual supervision fee of $5,000 for each additional Regulated Activity for which it has obtained a Financial Services Permission. \n",
            "Phrase: pay\n",
            "Original Label: ACT\n",
            "Predicted Label: ACT\n",
            "\n",
            "Example 14:\n",
            "Sentence: The Fund Manager, or the Person proposing to be the Fund Manager, of a Domestic Fund which is a Public Fund but is not an Umbrella Fund, must pay an annual registration renewal fee to the Regulator of $3,000, due at the commencement of each calendar year following the date of registration of the Public Fund. \n",
            "Phrase: Fund\n",
            "Original Label: DEF\n",
            "Predicted Label: DEF\n",
            "\n",
            "Example 15:\n",
            "Sentence: The Fund Manager, or the Person proposing to be the Fund Manager, of a Domestic Fund which is a Public Fund but is not an Umbrella Fund, must pay an annual registration renewal fee to the Regulator of $3,000, due at the commencement of each calendar year following the date of registration of the Public Fund. \n",
            "Phrase: Regulator\n",
            "Original Label: DEF\n",
            "Predicted Label: DEF\n",
            "\n",
            "Example 16:\n",
            "Sentence: The Fund Manager, or the Person proposing to be the Fund Manager, of a Domestic Fund which is a Public Fund but is not an Umbrella Fund, must pay an annual registration renewal fee to the Regulator of $3,000, due at the commencement of each calendar year following the date of registration of the Public Fund. \n",
            "Phrase: fee\n",
            "Original Label: DEF\n",
            "Predicted Label: DEF\n",
            "\n",
            "Example 17:\n",
            "Sentence: The Fund Manager, or the Person proposing to be the Fund Manager, of a Domestic Fund which is a Public Fund but is not an Umbrella Fund, must pay an annual registration renewal fee to the Regulator of $3,000, due at the commencement of each calendar year following the date of registration of the Public Fund. \n",
            "Phrase: Fund\n",
            "Original Label: DEF\n",
            "Predicted Label: DEF\n",
            "\n",
            "Example 18:\n",
            "Sentence: The Fund Manager, or the Person proposing to be the Fund Manager, of a Domestic Fund which is a Public Fund but is not an Umbrella Fund, must pay an annual registration renewal fee to the Regulator of $3,000, due at the commencement of each calendar year following the date of registration of the Public Fund. \n",
            "Phrase: Fund\n",
            "Original Label: DEF\n",
            "Predicted Label: DEF\n",
            "\n",
            "Example 19:\n",
            "Sentence: The Fund Manager, or the Person proposing to be the Fund Manager, of a Domestic Fund which is a Public Fund but is not an Umbrella Fund, must pay an annual registration renewal fee to the Regulator of $3,000, due at the commencement of each calendar year following the date of registration of the Public Fund. \n",
            "Phrase: Fund\n",
            "Original Label: DEF\n",
            "Predicted Label: DEF\n",
            "\n",
            "Example 20:\n",
            "Sentence: The Fund Manager, or the Person proposing to be the Fund Manager, of a Domestic Fund which is a Public Fund but is not an Umbrella Fund, must pay an annual registration renewal fee to the Regulator of $3,000, due at the commencement of each calendar year following the date of registration of the Public Fund. \n",
            "Phrase: Fund Manager\n",
            "Original Label: DEF\n",
            "Predicted Label: DEF\n",
            "\n",
            "Example 21:\n",
            "Sentence: The Fund Manager, or the Person proposing to be the Fund Manager, of a Domestic Fund which is a Public Fund but is not an Umbrella Fund, must pay an annual registration renewal fee to the Regulator of $3,000, due at the commencement of each calendar year following the date of registration of the Public Fund. \n",
            "Phrase: Person\n",
            "Original Label: DEF\n",
            "Predicted Label: DEF\n",
            "\n",
            "Example 22:\n",
            "Sentence: The Fund Manager, or the Person proposing to be the Fund Manager, of a Domestic Fund which is a Public Fund but is not an Umbrella Fund, must pay an annual registration renewal fee to the Regulator of $3,000, due at the commencement of each calendar year following the date of registration of the Public Fund. \n",
            "Phrase: Fund Manager\n",
            "Original Label: DEF\n",
            "Predicted Label: DEF\n",
            "\n",
            "Example 23:\n",
            "Sentence: The Fund Manager, or the Person proposing to be the Fund Manager, of a Domestic Fund which is a Public Fund but is not an Umbrella Fund, must pay an annual registration renewal fee to the Regulator of $3,000, due at the commencement of each calendar year following the date of registration of the Public Fund. \n",
            "Phrase: following the date\n",
            "Original Label: MIT\n",
            "Predicted Label: MIT\n",
            "\n",
            "Example 24:\n",
            "Sentence: The Fund Manager, or the Person proposing to be the Fund Manager, of a Domestic Fund which is a Public Fund but is not an Umbrella Fund, must pay an annual registration renewal fee to the Regulator of $3,000, due at the commencement of each calendar year following the date of registration of the Public Fund. \n",
            "Phrase: at the commencement of\n",
            "Original Label: MIT\n",
            "Predicted Label: MIT\n",
            "\n",
            "Example 25:\n",
            "Sentence: The Fund Manager, or the Person proposing to be the Fund Manager, of a Domestic Fund which is a Public Fund but is not an Umbrella Fund, must pay an annual registration renewal fee to the Regulator of $3,000, due at the commencement of each calendar year following the date of registration of the Public Fund. \n",
            "Phrase: must pay an annual registration renewal fee to\n",
            "Original Label: MIT\n",
            "Predicted Label: MIT\n",
            "\n",
            "Example 26:\n",
            "Sentence: The Fund Manager, or the Person proposing to be the Fund Manager, of a Domestic Fund which is a Public Fund but is not an Umbrella Fund, must pay an annual registration renewal fee to the Regulator of $3,000, due at the commencement of each calendar year following the date of registration of the Public Fund. \n",
            "Phrase: Fund\n",
            "Original Label: PROD\n",
            "Predicted Label: DEF\n",
            "\n",
            "Example 27:\n",
            "Sentence: The Fund Manager, or the Person proposing to be the Fund Manager, of a Domestic Fund which is a Public Fund but is not an Umbrella Fund, must pay an annual registration renewal fee to the Regulator of $3,000, due at the commencement of each calendar year following the date of registration of the Public Fund. \n",
            "Phrase: pay\n",
            "Original Label: ACT\n",
            "Predicted Label: ACT\n",
            "\n",
            "Example 28:\n",
            "Sentence: The Fund Manager, or the Person proposing to be the Fund Manager, of a Domestic Fund which is a Public Fund but is not an Umbrella Fund, must pay an annual registration renewal fee to the Regulator of $3,000, due at the commencement of each calendar year following the date of registration of the Public Fund. \n",
            "Phrase: Fund\n",
            "Original Label: PROD\n",
            "Predicted Label: DEF\n",
            "\n",
            "Example 29:\n",
            "Sentence: The Fund Manager, or the Person proposing to be the Fund Manager, of a Domestic Fund which is a Public Fund but is not an Umbrella Fund, must pay an annual registration renewal fee to the Regulator of $3,000, due at the commencement of each calendar year following the date of registration of the Public Fund. \n",
            "Phrase: Fund\n",
            "Original Label: PROD\n",
            "Predicted Label: DEF\n",
            "\n",
            "Example 30:\n",
            "Sentence: The Fund Manager, or the Person proposing to be the Fund Manager, of a Domestic Fund which is a Public Fund but is not an Umbrella Fund, must pay an annual registration renewal fee to the Regulator of $3,000, due at the commencement of each calendar year following the date of registration of the Public Fund. \n",
            "Phrase: Fund\n",
            "Original Label: PROD\n",
            "Predicted Label: DEF\n",
            "\n",
            "Example 31:\n",
            "Sentence: The Fund Manager, or the Person proposing to be the Fund Manager, of a Domestic Fund which is a Public Fund but is not an Umbrella Fund, must pay an annual registration renewal fee to the Regulator of $3,000, due at the commencement of each calendar year following the date of registration of the Public Fund. \n",
            "Phrase: Fund\n",
            "Original Label: PROD\n",
            "Predicted Label: DEF\n",
            "\n",
            "Example 32:\n",
            "Sentence: The Fund Manager, or the Person proposing to be the Fund Manager, of a Domestic Fund which is a Public Fund but is not an Umbrella Fund, must pay an annual registration renewal fee to the Regulator of $3,000, due at the commencement of each calendar year following the date of registration of the Public Fund. \n",
            "Phrase: Fund\n",
            "Original Label: PROD\n",
            "Predicted Label: DEF\n",
            "\n",
            "Example 33:\n",
            "Sentence: The Fund Manager, or the Person proposing to be the Fund Manager, of a Domestic Fund which is a Public Fund but is not an Umbrella Fund, must pay an annual registration renewal fee to the Regulator of $3,000, due at the commencement of each calendar year following the date of registration of the Public Fund. \n",
            "Phrase: Regulator\n",
            "Original Label: ENT\n",
            "Predicted Label: DEF\n",
            "\n",
            "Example 34:\n",
            "Sentence: The Fund Manager, or the Person proposing to be the Fund Manager, of a Domestic Fund which is a Public Fund but is not an Umbrella Fund, must pay an annual registration renewal fee to the Regulator of $3,000, due at the commencement of each calendar year following the date of registration of the Public Fund. \n",
            "Phrase: Fund Manager\n",
            "Original Label: ENT\n",
            "Predicted Label: DEF\n",
            "\n",
            "Example 35:\n",
            "Sentence: The Fund Manager, or the Person proposing to be the Fund Manager, of a Domestic Fund which is a Public Fund but is not an Umbrella Fund, must pay an annual registration renewal fee to the Regulator of $3,000, due at the commencement of each calendar year following the date of registration of the Public Fund. \n",
            "Phrase: Person\n",
            "Original Label: ENT\n",
            "Predicted Label: DEF\n",
            "\n",
            "Example 36:\n",
            "Sentence: The Fund Manager, or the Person proposing to be the Fund Manager, of a Domestic Fund which is a Public Fund but is not an Umbrella Fund, must pay an annual registration renewal fee to the Regulator of $3,000, due at the commencement of each calendar year following the date of registration of the Public Fund. \n",
            "Phrase: Fund Manager\n",
            "Original Label: ENT\n",
            "Predicted Label: DEF\n",
            "\n",
            "Example 37:\n",
            "Sentence: subject to any required adjustment in accordance with Rule 3.10.2. \n",
            "Phrase: Rule\n",
            "Original Label: DEF\n",
            "Predicted Label: DEF\n",
            "\n",
            "Example 38:\n",
            "Sentence: subject to any required adjustment in accordance with Rule 3.10.2. \n",
            "Phrase: Rule 3.10.2\n",
            "Original Label: MIT\n",
            "Predicted Label: MIT\n",
            "\n",
            "Example 39:\n",
            "Sentence: subject to any required adjustment in accordance with Rule 3.10.2. \n",
            "Phrase: subject to any required adjustment in accordance with\n",
            "Original Label: MIT\n",
            "Predicted Label: RISK\n",
            "\n",
            "Example 40:\n",
            "Sentence: an application for the amendment of an approval as an Approved Person to perform a Controlled Function; \n",
            "Phrase: Person\n",
            "Original Label: DEF\n",
            "Predicted Label: ENT\n",
            "\n",
            "Example 41:\n",
            "Sentence: an application for the amendment of an approval as an Approved Person to perform a Controlled Function; \n",
            "Phrase: Approved Person\n",
            "Original Label: ENT\n",
            "Predicted Label: ENT\n",
            "\n",
            "Example 42:\n",
            "Sentence: A supplementary fee may be levied by the Regulatorin circumstances where it expects to incur substantial additional costs in dealing with a matter. Such circumstances could include, for example: \n",
            "Phrase: fee\n",
            "Original Label: DEF\n",
            "Predicted Label: DEF\n",
            "\n",
            "Example 43:\n",
            "Sentence: A supplementary fee may be levied by the Regulatorin circumstances where it expects to incur substantial additional costs in dealing with a matter. Such circumstances could include, for example: \n",
            "Phrase: could include\n",
            "Original Label: RISK\n",
            "Predicted Label: MIT\n",
            "\n",
            "Example 44:\n",
            "Sentence: A supplementary fee may be levied by the Regulatorin circumstances where it expects to incur substantial additional costs in dealing with a matter. Such circumstances could include, for example: \n",
            "Phrase: circumstances where it expects to incur\n",
            "Original Label: MIT\n",
            "Predicted Label: RISK\n",
            "\n",
            "Example 45:\n",
            "Sentence: A supplementary fee may be levied by the Regulatorin circumstances where it expects to incur substantial additional costs in dealing with a matter. Such circumstances could include, for example: \n",
            "Phrase: supplementary fee may be levied by\n",
            "Original Label: MIT\n",
            "Predicted Label: MIT\n",
            "\n",
            "Example 46:\n",
            "Sentence: A supplementary fee may be levied by the Regulatorin circumstances where it expects to incur substantial additional costs in dealing with a matter. Such circumstances could include, for example: \n",
            "Phrase: dealing with\n",
            "Original Label: ACT\n",
            "Predicted Label: ACT\n",
            "\n",
            "Example 47:\n",
            "Sentence: the lead arranger of a proposed issue of Securities, if the lead arranger is a Bank or is authorised to accept deposits, and supervised, by the Central Bank of the State; or \n",
            "Phrase: accept deposits\n",
            "Original Label: DEF\n",
            "Predicted Label: TECH\n",
            "\n",
            "Example 48:\n",
            "Sentence: the lead arranger of a proposed issue of Securities, if the lead arranger is a Bank or is authorised to accept deposits, and supervised, by the Central Bank of the State; or \n",
            "Phrase: Bank\n",
            "Original Label: DEF\n",
            "Predicted Label: DEF\n",
            "\n",
            "Example 49:\n",
            "Sentence: the lead arranger of a proposed issue of Securities, if the lead arranger is a Bank or is authorised to accept deposits, and supervised, by the Central Bank of the State; or \n",
            "Phrase: Securities\n",
            "Original Label: DEF\n",
            "Predicted Label: PROD\n",
            "\n",
            "Example 50:\n",
            "Sentence: the lead arranger of a proposed issue of Securities, if the lead arranger is a Bank or is authorised to accept deposits, and supervised, by the Central Bank of the State; or \n",
            "Phrase: deposits\n",
            "Original Label: TECH\n",
            "Predicted Label: DEF\n",
            "\n",
            "Example 51:\n",
            "Sentence: the lead arranger of a proposed issue of Securities, if the lead arranger is a Bank or is authorised to accept deposits, and supervised, by the Central Bank of the State; or \n",
            "Phrase: deposits\n",
            "Original Label: ACT\n",
            "Predicted Label: DEF\n",
            "\n",
            "Example 52:\n",
            "Sentence: the lead arranger of a proposed issue of Securities, if the lead arranger is a Bank or is authorised to accept deposits, and supervised, by the Central Bank of the State; or \n",
            "Phrase: Securities\n",
            "Original Label: PROD\n",
            "Predicted Label: PROD\n",
            "\n",
            "Example 53:\n",
            "Sentence: An Applicant for a Financial Services Permission to carry on the Regulated Activities of Effecting or Carrying Out Contracts of Insurance as a Captive Insurer (as a Class 1, Class 2, Class 3 or Class 4 Captive Insurer) must pay to the Regulator an initial authorisation fee of $5,000 \n",
            "Phrase: fee\n",
            "Original Label: DEF\n",
            "Predicted Label: DEF\n",
            "\n",
            "Example 54:\n",
            "Sentence: An Applicant for a Financial Services Permission to carry on the Regulated Activities of Effecting or Carrying Out Contracts of Insurance as a Captive Insurer (as a Class 1, Class 2, Class 3 or Class 4 Captive Insurer) must pay to the Regulator an initial authorisation fee of $5,000 \n",
            "Phrase: Regulator\n",
            "Original Label: DEF\n",
            "Predicted Label: DEF\n",
            "\n",
            "Example 55:\n",
            "Sentence: An Applicant for a Financial Services Permission to carry on the Regulated Activities of Effecting or Carrying Out Contracts of Insurance as a Captive Insurer (as a Class 1, Class 2, Class 3 or Class 4 Captive Insurer) must pay to the Regulator an initial authorisation fee of $5,000 \n",
            "Phrase: Insurer\n",
            "Original Label: DEF\n",
            "Predicted Label: DEF\n",
            "\n",
            "Example 56:\n",
            "Sentence: An Applicant for a Financial Services Permission to carry on the Regulated Activities of Effecting or Carrying Out Contracts of Insurance as a Captive Insurer (as a Class 1, Class 2, Class 3 or Class 4 Captive Insurer) must pay to the Regulator an initial authorisation fee of $5,000 \n",
            "Phrase: Insurer\n",
            "Original Label: DEF\n",
            "Predicted Label: DEF\n",
            "\n",
            "Example 57:\n",
            "Sentence: An Applicant for a Financial Services Permission to carry on the Regulated Activities of Effecting or Carrying Out Contracts of Insurance as a Captive Insurer (as a Class 1, Class 2, Class 3 or Class 4 Captive Insurer) must pay to the Regulator an initial authorisation fee of $5,000 \n",
            "Phrase: Contracts of Insurance\n",
            "Original Label: DEF\n",
            "Predicted Label: DEF\n",
            "\n",
            "Example 58:\n",
            "Sentence: An Applicant for a Financial Services Permission to carry on the Regulated Activities of Effecting or Carrying Out Contracts of Insurance as a Captive Insurer (as a Class 1, Class 2, Class 3 or Class 4 Captive Insurer) must pay to the Regulator an initial authorisation fee of $5,000 \n",
            "Phrase: Regulated Activities\n",
            "Original Label: DEF\n",
            "Predicted Label: ACT\n",
            "\n",
            "Example 59:\n",
            "Sentence: An Applicant for a Financial Services Permission to carry on the Regulated Activities of Effecting or Carrying Out Contracts of Insurance as a Captive Insurer (as a Class 1, Class 2, Class 3 or Class 4 Captive Insurer) must pay to the Regulator an initial authorisation fee of $5,000 \n",
            "Phrase: an initial authorisation fee\n",
            "Original Label: MIT\n",
            "Predicted Label: MIT\n",
            "\n",
            "Example 60:\n",
            "Sentence: An Applicant for a Financial Services Permission to carry on the Regulated Activities of Effecting or Carrying Out Contracts of Insurance as a Captive Insurer (as a Class 1, Class 2, Class 3 or Class 4 Captive Insurer) must pay to the Regulator an initial authorisation fee of $5,000 \n",
            "Phrase: must pay\n",
            "Original Label: MIT\n",
            "Predicted Label: MIT\n",
            "\n",
            "Example 61:\n",
            "Sentence: An Applicant for a Financial Services Permission to carry on the Regulated Activities of Effecting or Carrying Out Contracts of Insurance as a Captive Insurer (as a Class 1, Class 2, Class 3 or Class 4 Captive Insurer) must pay to the Regulator an initial authorisation fee of $5,000 \n",
            "Phrase: authorisation\n",
            "Original Label: FS\n",
            "Predicted Label: FS\n",
            "\n",
            "Example 62:\n",
            "Sentence: An Applicant for a Financial Services Permission to carry on the Regulated Activities of Effecting or Carrying Out Contracts of Insurance as a Captive Insurer (as a Class 1, Class 2, Class 3 or Class 4 Captive Insurer) must pay to the Regulator an initial authorisation fee of $5,000 \n",
            "Phrase: pay to\n",
            "Original Label: ACT\n",
            "Predicted Label: ACT\n",
            "\n",
            "Example 63:\n",
            "Sentence: An Applicant for a Financial Services Permission to carry on the Regulated Activities of Effecting or Carrying Out Contracts of Insurance as a Captive Insurer (as a Class 1, Class 2, Class 3 or Class 4 Captive Insurer) must pay to the Regulator an initial authorisation fee of $5,000 \n",
            "Phrase: Carrying Out\n",
            "Original Label: ACT\n",
            "Predicted Label: ACT\n",
            "\n",
            "Example 64:\n",
            "Sentence: An Applicant for a Financial Services Permission to carry on the Regulated Activities of Effecting or Carrying Out Contracts of Insurance as a Captive Insurer (as a Class 1, Class 2, Class 3 or Class 4 Captive Insurer) must pay to the Regulator an initial authorisation fee of $5,000 \n",
            "Phrase: Regulated Activities\n",
            "Original Label: ACT\n",
            "Predicted Label: ACT\n",
            "\n",
            "Example 65:\n",
            "Sentence: An Applicant for a Financial Services Permission to carry on the Regulated Activities of Effecting or Carrying Out Contracts of Insurance as a Captive Insurer (as a Class 1, Class 2, Class 3 or Class 4 Captive Insurer) must pay to the Regulator an initial authorisation fee of $5,000 \n",
            "Phrase: carry on\n",
            "Original Label: ACT\n",
            "Predicted Label: ACT\n",
            "\n",
            "Example 66:\n",
            "Sentence: An Applicant for a Financial Services Permission to carry on the Regulated Activities of Effecting or Carrying Out Contracts of Insurance as a Captive Insurer (as a Class 1, Class 2, Class 3 or Class 4 Captive Insurer) must pay to the Regulator an initial authorisation fee of $5,000 \n",
            "Phrase: Regulator\n",
            "Original Label: ENT\n",
            "Predicted Label: DEF\n",
            "\n",
            "Example 67:\n",
            "Sentence: An Applicant for a Financial Services Permission to carry on the Regulated Activities of Effecting or Carrying Out Contracts of Insurance as a Captive Insurer (as a Class 1, Class 2, Class 3 or Class 4 Captive Insurer) must pay to the Regulator an initial authorisation fee of $5,000 \n",
            "Phrase: Captive Insurer\n",
            "Original Label: ENT\n",
            "Predicted Label: DEF\n",
            "\n",
            "Example 68:\n",
            "Sentence: An Applicant for a Financial Services Permission to carry on the Regulated Activities of Effecting or Carrying Out Contracts of Insurance as a Captive Insurer (as a Class 1, Class 2, Class 3 or Class 4 Captive Insurer) must pay to the Regulator an initial authorisation fee of $5,000 \n",
            "Phrase: Captive Insurer\n",
            "Original Label: ENT\n",
            "Predicted Label: DEF\n",
            "\n",
            "Example 69:\n",
            "Sentence: An Applicant for a Financial Services Permission to carry on the Regulated Activities of Effecting or Carrying Out Contracts of Insurance as a Captive Insurer (as a Class 1, Class 2, Class 3 or Class 4 Captive Insurer) must pay to the Regulator an initial authorisation fee of $5,000 \n",
            "Phrase: Effecting or Carrying Out Contracts of Insurance as a Captive Insurer (as a Class 1, Class 2, Class 3 or Class 4 Captive Insurer) must pay\n",
            "Original Label: PERM\n",
            "Predicted Label: ACT\n",
            "\n",
            "Example 70:\n",
            "Sentence: must pay to the Regulator an application fee of $500 for each Approved Person for whom it is seeking authorisation, to amend the scope of his authorisation, or to substitute as an Approved Person (as applicable). \n",
            "Phrase: Person\n",
            "Original Label: DEF\n",
            "Predicted Label: DEF\n",
            "\n",
            "Example 71:\n",
            "Sentence: must pay to the Regulator an application fee of $500 for each Approved Person for whom it is seeking authorisation, to amend the scope of his authorisation, or to substitute as an Approved Person (as applicable). \n",
            "Phrase: Person\n",
            "Original Label: DEF\n",
            "Predicted Label: DEF\n",
            "\n",
            "Example 72:\n",
            "Sentence: must pay to the Regulator an application fee of $500 for each Approved Person for whom it is seeking authorisation, to amend the scope of his authorisation, or to substitute as an Approved Person (as applicable). \n",
            "Phrase: Regulator\n",
            "Original Label: DEF\n",
            "Predicted Label: ENT\n",
            "\n",
            "Example 73:\n",
            "Sentence: must pay to the Regulator an application fee of $500 for each Approved Person for whom it is seeking authorisation, to amend the scope of his authorisation, or to substitute as an Approved Person (as applicable). \n",
            "Phrase: Person\n",
            "Original Label: DEF\n",
            "Predicted Label: DEF\n",
            "\n",
            "Example 74:\n",
            "Sentence: must pay to the Regulator an application fee of $500 for each Approved Person for whom it is seeking authorisation, to amend the scope of his authorisation, or to substitute as an Approved Person (as applicable). \n",
            "Phrase: fee\n",
            "Original Label: DEF\n",
            "Predicted Label: DEF\n",
            "\n",
            "Example 75:\n",
            "Sentence: must pay to the Regulator an application fee of $500 for each Approved Person for whom it is seeking authorisation, to amend the scope of his authorisation, or to substitute as an Approved Person (as applicable). \n",
            "Phrase: Regulator\n",
            "Original Label: DEF\n",
            "Predicted Label: ENT\n",
            "\n",
            "Example 76:\n",
            "Sentence: must pay to the Regulator an application fee of $500 for each Approved Person for whom it is seeking authorisation, to amend the scope of his authorisation, or to substitute as an Approved Person (as applicable). \n",
            "Phrase: or to substitute as\n",
            "Original Label: MIT\n",
            "Predicted Label: MIT\n",
            "\n",
            "Example 77:\n",
            "Sentence: must pay to the Regulator an application fee of $500 for each Approved Person for whom it is seeking authorisation, to amend the scope of his authorisation, or to substitute as an Approved Person (as applicable). \n",
            "Phrase: for whom it is seeking authorisation authorisation\n",
            "Original Label: RISK\n",
            "Predicted Label: RISK\n",
            "\n",
            "Example 78:\n",
            "Sentence: must pay to the Regulator an application fee of $500 for each Approved Person for whom it is seeking authorisation, to amend the scope of his authorisation, or to substitute as an Approved Person (as applicable). \n",
            "Phrase: to amend the scope of each\n",
            "Original Label: MIT\n",
            "Predicted Label: MIT\n",
            "\n",
            "Example 79:\n",
            "Sentence: must pay to the Regulator an application fee of $500 for each Approved Person for whom it is seeking authorisation, to amend the scope of his authorisation, or to substitute as an Approved Person (as applicable). \n",
            "Phrase: seeking authorisation\n",
            "Original Label: MIT\n",
            "Predicted Label: TECH\n",
            "\n",
            "Example 80:\n",
            "Sentence: must pay to the Regulator an application fee of $500 for each Approved Person for whom it is seeking authorisation, to amend the scope of his authorisation, or to substitute as an Approved Person (as applicable). \n",
            "Phrase: an application fee of $\n",
            "Original Label: MIT\n",
            "Predicted Label: MIT\n",
            "\n",
            "Example 81:\n",
            "Sentence: must pay to the Regulator an application fee of $500 for each Approved Person for whom it is seeking authorisation, to amend the scope of his authorisation, or to substitute as an Approved Person (as applicable). \n",
            "Phrase: must pay\n",
            "Original Label: MIT\n",
            "Predicted Label: MIT\n",
            "\n",
            "Example 82:\n",
            "Sentence: must pay to the Regulator an application fee of $500 for each Approved Person for whom it is seeking authorisation, to amend the scope of his authorisation, or to substitute as an Approved Person (as applicable). \n",
            "Phrase: authorisation\n",
            "Original Label: FS\n",
            "Predicted Label: FS\n",
            "\n",
            "Example 83:\n",
            "Sentence: must pay to the Regulator an application fee of $500 for each Approved Person for whom it is seeking authorisation, to amend the scope of his authorisation, or to substitute as an Approved Person (as applicable). \n",
            "Phrase: authorisation\n",
            "Original Label: FS\n",
            "Predicted Label: FS\n",
            "\n",
            "Example 84:\n",
            "Sentence: must pay to the Regulator an application fee of $500 for each Approved Person for whom it is seeking authorisation, to amend the scope of his authorisation, or to substitute as an Approved Person (as applicable). \n",
            "Phrase: authorisation\n",
            "Original Label: FS\n",
            "Predicted Label: FS\n",
            "\n",
            "Example 85:\n",
            "Sentence: must pay to the Regulator an application fee of $500 for each Approved Person for whom it is seeking authorisation, to amend the scope of his authorisation, or to substitute as an Approved Person (as applicable). \n",
            "Phrase: pay\n",
            "Original Label: ACT\n",
            "Predicted Label: ACT\n",
            "\n",
            "Example 86:\n",
            "Sentence: must pay to the Regulator an application fee of $500 for each Approved Person for whom it is seeking authorisation, to amend the scope of his authorisation, or to substitute as an Approved Person (as applicable). \n",
            "Phrase: Person\n",
            "Original Label: ENT\n",
            "Predicted Label: DEF\n",
            "\n",
            "Example 87:\n",
            "Sentence: must pay to the Regulator an application fee of $500 for each Approved Person for whom it is seeking authorisation, to amend the scope of his authorisation, or to substitute as an Approved Person (as applicable). \n",
            "Phrase: Person\n",
            "Original Label: ENT\n",
            "Predicted Label: DEF\n",
            "\n",
            "Example 88:\n",
            "Sentence: must pay to the Regulator an application fee of $500 for each Approved Person for whom it is seeking authorisation, to amend the scope of his authorisation, or to substitute as an Approved Person (as applicable). \n",
            "Phrase: Regulator\n",
            "Original Label: ENT\n",
            "Predicted Label: ENT\n",
            "\n",
            "Example 89:\n",
            "Sentence: must pay to the Regulator an application fee of $500 for each Approved Person for whom it is seeking authorisation, to amend the scope of his authorisation, or to substitute as an Approved Person (as applicable). \n",
            "Phrase: Person\n",
            "Original Label: ENT\n",
            "Predicted Label: DEF\n",
            "\n",
            "Example 90:\n",
            "Sentence: must pay to the Regulator an application fee of $500 for each Approved Person for whom it is seeking authorisation, to amend the scope of his authorisation, or to substitute as an Approved Person (as applicable). \n",
            "Phrase: Regulator\n",
            "Original Label: ENT\n",
            "Predicted Label: ENT\n",
            "\n",
            "Example 91:\n",
            "Sentence: The Regulator retains full discretion to reduce or waive all or part of the initial authorisation fee under Rule 3.13.1 above. \n",
            "Phrase: Rule\n",
            "Original Label: DEF\n",
            "Predicted Label: DEF\n",
            "\n",
            "Example 92:\n",
            "Sentence: The Regulator retains full discretion to reduce or waive all or part of the initial authorisation fee under Rule 3.13.1 above. \n",
            "Phrase: fee\n",
            "Original Label: DEF\n",
            "Predicted Label: DEF\n",
            "\n",
            "Example 93:\n",
            "Sentence: The Regulator retains full discretion to reduce or waive all or part of the initial authorisation fee under Rule 3.13.1 above. \n",
            "Phrase: Regulator\n",
            "Original Label: DEF\n",
            "Predicted Label: DEF\n",
            "\n",
            "Example 94:\n",
            "Sentence: The Regulator retains full discretion to reduce or waive all or part of the initial authorisation fee under Rule 3.13.1 above. \n",
            "Phrase: Rule 3.13.1\n",
            "Original Label: MIT\n",
            "Predicted Label: MIT\n",
            "\n",
            "Example 95:\n",
            "Sentence: The Regulator retains full discretion to reduce or waive all or part of the initial authorisation fee under Rule 3.13.1 above. \n",
            "Phrase: authorisation\n",
            "Original Label: FS\n",
            "Predicted Label: FS\n",
            "\n",
            "Example 96:\n",
            "Sentence: The Regulator retains full discretion to reduce or waive all or part of the initial authorisation fee under Rule 3.13.1 above. \n",
            "Phrase: Regulator\n",
            "Original Label: ENT\n",
            "Predicted Label: DEF\n",
            "\n",
            "Example 97:\n",
            "Sentence: The Regulator will accept payment of a fee in USD from a member of the Applicants Group, the Applicants Parent, the Applicants legal advisor or a Person who has applied to be a Controller in relation to the Applicant but only where: \n",
            "Phrase: Controller\n",
            "Original Label: DEF\n",
            "Predicted Label: DEF\n",
            "\n",
            "Example 98:\n",
            "Sentence: The Regulator will accept payment of a fee in USD from a member of the Applicants Group, the Applicants Parent, the Applicants legal advisor or a Person who has applied to be a Controller in relation to the Applicant but only where: \n",
            "Phrase: Person\n",
            "Original Label: DEF\n",
            "Predicted Label: DEF\n",
            "\n",
            "Example 99:\n",
            "Sentence: The Regulator will accept payment of a fee in USD from a member of the Applicants Group, the Applicants Parent, the Applicants legal advisor or a Person who has applied to be a Controller in relation to the Applicant but only where: \n",
            "Phrase: Parent\n",
            "Original Label: DEF\n",
            "Predicted Label: DEF\n",
            "\n",
            "Example 100:\n",
            "Sentence: The Regulator will accept payment of a fee in USD from a member of the Applicants Group, the Applicants Parent, the Applicants legal advisor or a Person who has applied to be a Controller in relation to the Applicant but only where: \n",
            "Phrase: Group\n",
            "Original Label: DEF\n",
            "Predicted Label: DEF\n",
            "\n"
          ]
        }
      ]
    }
  ]
}